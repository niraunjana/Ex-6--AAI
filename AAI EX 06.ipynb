{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711b6f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sec\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\sec\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\sec\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sec\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sec\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sec\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3ff26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SEC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SEC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SEC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#import wordnet\n",
    "nltk.download( 'punkt' )\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download( 'averaged_perceptron_tagger' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d10777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is the field of study that uses scientific methods and algorithms \n"
     ]
    }
   ],
   "source": [
    "sentence=input ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776428e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize the sentence into words\n",
    "words = word_tokenize(sentence)\n",
    "# Identify the parts of speech for each word\n",
    "pos_tags= nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e882bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data NNP\n",
      "science NN\n",
      "is VBZ\n",
      "the DT\n",
      "field NN\n",
      "of IN\n",
      "study NN\n",
      "that WDT\n",
      "uses VBZ\n",
      "scientific JJ\n",
      "methods NNS\n",
      "and CC\n",
      "algorithms NN\n"
     ]
    }
   ],
   "source": [
    "# Print the parts of speech\n",
    "for word, tag in pos_tags:\n",
    "    print(word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782ccb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms :  {'discipline', 'scientific', 'usage', 'canvas', 'work', 'habituate', 'enjoyment', 'consider', 'force_field', 'manipulation', 'theater', 'playing_area', 'represent', 'orbit', 'plain', 'United_States', 'expend', 'live', 'use_of_goods_and_services', 'utilise', 'function', 'purpose', 'subject_area', 'theater_of_operations', 'use', 'algorithmic_rule', 'report', 'field_of_force', 'cost', 'usance', 'method_acting', 'analyse', 'US', 'algorithmic_program', 'employment', 'meditate', 'sphere', 'written_report', 'flying_field', 'utilisation', 'athletic_field', 'subject', 'consumption', 'information', 'utilization', 'USA', 'examine', 'read', 'study', 'line_of_business', 'hit_the_books', 'make_up', 'canvass', 'embody', 'contemplate', 'employ', 'take', 'field_of_view', 'theatre_of_operations', 'field_of_honor', 'airfield', 'domain', 'field_of_study', 'apply', 'utilize', 'learn', 'be', 'cogitation', 'field_of_operation', 'survey', 'follow', 'field_of_operations', 'champaign', 'role', 'method', 'comprise', 'landing_field', 'bailiwick', 'subject_field', 'exist', 'theatre', 'playing_field', 'economic_consumption', 'sketch', 'area', 'science', 'battleground', 'battlefield', 'U.S.A.', 'U.S.', 'datum', 'algorithm', 'United_States_of_America', 'America', 'practice', 'skill', 'analyze', 'habit', 'scientific_discipline', 'arena', 'field', 'field_of_battle', 'equal', 'data_point', 'constitute', 'personify', 'data', 'exercise', 'the_States'}\n",
      "Antonyms :  {'unscientific', 'differ'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Identify synonyms and antonyms for each word\n",
    "synonyms =[]\n",
    "antonyms =[]\n",
    "for word in words:\n",
    "\tfor syn in wordnet.synsets(word) :\n",
    "\t\tfor lemma in syn.lemmas():\n",
    "\t\t\tsynonyms . append (lemma . name( ) )\n",
    "\t\t\tif lemma . antonyms():\n",
    "\t\t\t\tantonyms . append ( lemma. antonyms ( ) [0] . name ( ) )\n",
    "# Print the synonyms and antonyms\n",
    "print ( \"Synonyms : \" ,set (synonyms) )\n",
    "print ( \"Antonyms : \" ,set(antonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f9217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
